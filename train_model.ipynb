{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4267194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.0.22)\n",
      "Requirement already satisfied: torchvision in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.24.1+cu128)\n",
      "Requirement already satisfied: torch in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.9.1+cu128)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from timm) (6.0.3)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from timm) (0.36.0)\n",
      "Requirement already satisfied: safetensors in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from timm) (0.6.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torchvision) (2.3.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub->timm) (2.32.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub->timm) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub->timm) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub->timm) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\siddiq\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub->timm) (2025.10.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install timm torchvision torch torchvision torchaudio tqdm scikit-learn matplotlib pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bd6135",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eea23ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "import timm\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f836018",
   "metadata": {},
   "source": [
    "## KONFIGURASI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a2e33c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"dataset\"\n",
    "TRAIN_CSV = \"train.csv\"\n",
    "VAL_CSV = \"val.csv\"\n",
    "TEST_CSV = \"test.csv\"\n",
    "\n",
    "# Ganti ini kalau mau model lain\n",
    "MODEL_NAME = \"vit_tiny_patch16_224\"    # opsi 1\n",
    "# MODEL_NAME = \"deit_tiny_patch16_224\" # opsi 2, jalankan di run terpisah\n",
    "\n",
    "MODEL_TAG = MODEL_NAME.replace(\"_patch16_224\", \"\").replace(\"_tiny\", \"_tiny\")\n",
    "\n",
    "NUM_CLASSES = 5\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 15\n",
    "LR = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "NUM_WORKERS = 0\n",
    "SEED = 42\n",
    "\n",
    "DEVICE = \"cpu\"\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee37c3a",
   "metadata": {},
   "source": [
    "## SEEDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf20151a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2401c978",
   "metadata": {},
   "source": [
    "## KELAS DAN MAPPING LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "353d38ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class to idx mapping: {'bakso': 0, 'gado_gado': 1, 'nasi_goreng': 2, 'rendang': 3, 'soto_ayam': 4}\n"
     ]
    }
   ],
   "source": [
    "CLASSES = [\"bakso\", \"gado_gado\", \"nasi_goreng\", \"rendang\", \"soto_ayam\"]\n",
    "CLASS_TO_IDX = {c: i for i, c in enumerate(CLASSES)}\n",
    "IDX_TO_CLASS = {i: c for c, i in CLASS_TO_IDX.items()}\n",
    "\n",
    "print(\"Class to idx mapping:\", CLASS_TO_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8768380c",
   "metadata": {},
   "source": [
    "## DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "902fc11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoodDataset(Dataset):\n",
    "    def __init__(self, csv_path, img_dir, transform=None):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.filenames = self.df[\"filename\"].values\n",
    "        self.labels_str = self.df[\"label\"].values\n",
    "        self.labels = [CLASS_TO_IDX[label] for label in self.labels_str]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.filenames[idx]\n",
    "        label = self.labels[idx]\n",
    "    \n",
    "        img_path = os.path.join(self.img_dir, filename)\n",
    "    \n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Gagal membuka gambar: {img_path} | Error: {e}\")\n",
    "    \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "    \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec81f95",
   "metadata": {},
   "source": [
    "## TRANSFORMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ebd5a7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=(0.485, 0.456, 0.406),\n",
    "        std=(0.229, 0.224, 0.225),\n",
    "    ),\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=(0.485, 0.456, 0.406),\n",
    "        std=(0.229, 0.224, 0.225),\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80480496",
   "metadata": {},
   "source": [
    "## DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1aa91386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2228 | Val: 278 | Test: 279\n"
     ]
    }
   ],
   "source": [
    "train_dataset = FoodDataset(TRAIN_CSV, DATA_DIR, transform=train_transform)\n",
    "val_dataset   = FoodDataset(VAL_CSV, DATA_DIR, transform=eval_transform)\n",
    "test_dataset  = FoodDataset(TEST_CSV, DATA_DIR, transform=eval_transform)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                        num_workers=NUM_WORKERS, pin_memory=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                         num_workers=NUM_WORKERS, pin_memory=False)\n",
    "\n",
    "print(f\"Train: {len(train_dataset)} | Val: {len(val_dataset)} | Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e684a300",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4738b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== INFO PARAMETER MODEL =====\n",
      "Model name          : vit_tiny_patch16_224\n",
      "Total params        : 5,525,381\n",
      "Trainable params    : 5,525,381\n",
      "Non-trainable params: 0\n",
      "Approx. size        : 21.08 MB\n"
     ]
    }
   ],
   "source": [
    "def create_model(model_name, num_classes):\n",
    "    model = timm.create_model(\n",
    "        model_name,\n",
    "        pretrained=True,\n",
    "        num_classes=num_classes\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = create_model(MODEL_NAME, NUM_CLASSES)\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Info parameter\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "non_trainable_params = total_params - trainable_params\n",
    "model_size_mb = total_params * 4 / (1024 ** 2)  # float32 → 4 byte\n",
    "\n",
    "print(\"===== INFO PARAMETER MODEL =====\")\n",
    "print(f\"Model name          : {MODEL_NAME}\")\n",
    "print(f\"Total params        : {total_params:,}\")\n",
    "print(f\"Trainable params    : {trainable_params:,}\")\n",
    "print(f\"Non-trainable params: {non_trainable_params:,}\")\n",
    "print(f\"Approx. size        : {model_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc172fe6",
   "metadata": {},
   "source": [
    "## LOSS, OPTIMIZER, SCHEDULER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4d409a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9b76e0",
   "metadata": {},
   "source": [
    "## FUNGSI TRAINING & VALIDASI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "56e917a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    running_total = 0\n",
    "\n",
    "    pbar = tqdm(loader, desc=\"Train\", leave=False)\n",
    "    for images, labels in pbar:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct = (preds == labels).sum().item()\n",
    "        total = labels.size(0)\n",
    "\n",
    "        running_loss += loss.item() * total\n",
    "        running_correct += correct\n",
    "        running_total += total\n",
    "\n",
    "        pbar.set_postfix({\n",
    "            \"loss\": f\"{loss.item():.4f}\",\n",
    "            \"acc\": f\"{correct / total:.4f}\"\n",
    "        })\n",
    "\n",
    "    epoch_loss = running_loss / running_total\n",
    "    epoch_acc = running_correct / running_total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    running_total = 0\n",
    "\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc=\"Eval\", leave=False)\n",
    "        for images, labels in pbar:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            preds = outputs.argmax(dim=1)\n",
    "\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "            running_correct += (preds == labels).sum().item()\n",
    "            running_total += labels.size(0)\n",
    "\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "\n",
    "    epoch_loss = running_loss / running_total\n",
    "    epoch_acc = running_correct / running_total\n",
    "\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "\n",
    "    return epoch_loss, epoch_acc, all_labels, all_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd1e91e",
   "metadata": {},
   "source": [
    "## TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1977499d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Epoch 1/15 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   2%|▏         | 3/140 [00:07<05:51,  2.57s/it, loss=2.1152, acc=0.3125]c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\PIL\\Image.py:1039: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\PIL\\Image.py:1039: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6294 | Train Acc: 0.7630\n",
      "Val   Loss: 0.1371 | Val   Acc: 0.9460\n",
      ">> Best model updated!\n",
      "\n",
      "===== Epoch 2/15 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1786 | Train Acc: 0.9381\n",
      "Val   Loss: 0.1685 | Val   Acc: 0.9281\n",
      "\n",
      "===== Epoch 3/15 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1091 | Train Acc: 0.9560\n",
      "Val   Loss: 0.1098 | Val   Acc: 0.9748\n",
      ">> Best model updated!\n",
      "\n",
      "===== Epoch 4/15 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0626 | Train Acc: 0.9758\n",
      "Val   Loss: 0.0803 | Val   Acc: 0.9712\n",
      "\n",
      "===== Epoch 5/15 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0445 | Train Acc: 0.9829\n",
      "Val   Loss: 0.0653 | Val   Acc: 0.9784\n",
      ">> Best model updated!\n",
      "\n",
      "===== Epoch 6/15 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0340 | Train Acc: 0.9897\n",
      "Val   Loss: 0.0649 | Val   Acc: 0.9820\n",
      ">> Best model updated!\n",
      "\n",
      "===== Epoch 7/15 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0218 | Train Acc: 0.9928\n",
      "Val   Loss: 0.0653 | Val   Acc: 0.9784\n",
      "\n",
      "===== Epoch 8/15 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0154 | Train Acc: 0.9951\n",
      "Val   Loss: 0.0834 | Val   Acc: 0.9676\n",
      "\n",
      "===== Epoch 9/15 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0043 | Train Acc: 0.9991\n",
      "Val   Loss: 0.0546 | Val   Acc: 0.9784\n",
      "\n",
      "===== Epoch 10/15 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0064 | Train Acc: 0.9973\n",
      "Val   Loss: 0.0603 | Val   Acc: 0.9748\n",
      "\n",
      "===== Epoch 11/15 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0036 | Train Acc: 0.9987\n",
      "Val   Loss: 0.0483 | Val   Acc: 0.9820\n",
      "\n",
      "===== Epoch 12/15 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0036 | Train Acc: 0.9987\n",
      "Val   Loss: 0.0507 | Val   Acc: 0.9820\n",
      "\n",
      "===== Epoch 13/15 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0027 | Train Acc: 0.9996\n",
      "Val   Loss: 0.0602 | Val   Acc: 0.9820\n",
      "\n",
      "===== Epoch 14/15 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0020 | Train Acc: 0.9996\n",
      "Val   Loss: 0.0561 | Val   Acc: 0.9820\n",
      "\n",
      "===== Epoch 15/15 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0009 | Train Acc: 1.0000\n",
      "Val   Loss: 0.0558 | Val   Acc: 0.9820\n",
      "Best model saved to: checkpoints\\vit_tiny_best.pth\n",
      "Training history saved to: vit_tiny_history.npy\n"
     ]
    }
   ],
   "source": [
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"train_acc\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_acc\": []\n",
    "}\n",
    "\n",
    "best_val_acc = 0.0\n",
    "best_state_dict = None\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\n===== Epoch {epoch + 1}/{NUM_EPOCHS} =====\")\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, DEVICE)\n",
    "    val_loss, val_acc, val_labels, val_preds = evaluate(model, val_loader, criterion, DEVICE)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"train_acc\"].append(train_acc)\n",
    "    history[\"val_loss\"].append(val_loss)\n",
    "    history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_state_dict = model.state_dict()\n",
    "        print(\">> Best model updated!\")\n",
    "\n",
    "# Simpan model terbaik\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "model_path = os.path.join(\"checkpoints\", f\"{MODEL_TAG}_best.pth\")\n",
    "\n",
    "if best_state_dict is not None:\n",
    "    torch.save(best_state_dict, model_path)\n",
    "    print(f\"Best model saved to: {model_path}\")\n",
    "else:\n",
    "    print(\"WARNING: best_state_dict is None, model not saved.\")\n",
    "\n",
    "# Simpan history\n",
    "history_path = f\"{MODEL_TAG}_history.npy\"\n",
    "np.save(history_path, history)\n",
    "print(f\"Training history saved to: {history_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a130548c",
   "metadata": {},
   "source": [
    "## EVALUASI DI TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "85975499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== EVALUASI DI TEST SET =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0821 | Test Acc: 0.9857\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       bakso     0.9583    1.0000    0.9787        46\n",
      "   gado_gado     0.9839    1.0000    0.9919        61\n",
      " nasi_goreng     0.9844    0.9844    0.9844        64\n",
      "     rendang     1.0000    0.9841    0.9920        63\n",
      "   soto_ayam     1.0000    0.9556    0.9773        45\n",
      "\n",
      "    accuracy                         0.9857       279\n",
      "   macro avg     0.9853    0.9848    0.9848       279\n",
      "weighted avg     0.9860    0.9857    0.9857       279\n",
      "\n",
      "Confusion matrix saved to: vit_tiny_confusion_matrix.png\n",
      "Confusion matrix saved to: vit_tiny_confusion_matrix.png\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== EVALUASI DI TEST SET =====\")\n",
    "\n",
    "if best_state_dict is not None:\n",
    "    model.load_state_dict(best_state_dict)\n",
    "\n",
    "test_loss, test_acc, test_labels, test_preds = evaluate(model, test_loader, criterion, DEVICE)\n",
    "print(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")\n",
    "\n",
    "target_names = CLASSES\n",
    "report = classification_report(test_labels, test_preds, target_names=target_names, digits=4)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Simpan classification report ke file\n",
    "with open(f\"{MODEL_TAG}_classification_report.txt\", \"w\") as f:\n",
    "    f.write(report)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "im = ax.imshow(cm, interpolation=\"nearest\")\n",
    "ax.figure.colorbar(im, ax=ax)\n",
    "ax.set(\n",
    "    xticks=np.arange(cm.shape[1]),\n",
    "    yticks=np.arange(cm.shape[0]),\n",
    "    xticklabels=target_names,\n",
    "    yticklabels=target_names,\n",
    "    ylabel=\"True label\",\n",
    "    xlabel=\"Predicted label\",\n",
    "    title=f\"Confusion Matrix - {MODEL_TAG}\"\n",
    ")\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"white\" if cm[i, j] > cm.max()/2 else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "cm_path = f\"{MODEL_TAG}_confusion_matrix.png\"\n",
    "plt.savefig(cm_path)\n",
    "plt.close()\n",
    "print(f\"Confusion matrix saved to: {cm_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba41c129",
   "metadata": {},
   "source": [
    "## PENGUKURAN WAKTU INFERENSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "707f0aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== MENGUKUR WAKTU INFERENSI (TEST SET, SUBSET) =====\n",
      "Images tested     : 279\n",
      "Total time        : 13.6402 s\n",
      "Avg time / image  : 48.8897 ms\n",
      "Throughput        : 20.45 images/s\n",
      "\n",
      "Summary saved to: vit_tiny_summary.csv\n",
      "Selesai.\n",
      "Images tested     : 279\n",
      "Total time        : 13.6402 s\n",
      "Avg time / image  : 48.8897 ms\n",
      "Throughput        : 20.45 images/s\n",
      "\n",
      "Summary saved to: vit_tiny_summary.csv\n",
      "Selesai.\n"
     ]
    }
   ],
   "source": [
    "def measure_inference_time(model, loader, device, num_warmup=20, max_images=300):\n",
    "    model.eval()\n",
    "    total_images = 0\n",
    "    total_time = 0.0\n",
    "\n",
    "    # Warm-up\n",
    "    with torch.no_grad():\n",
    "        for i, (images, _) in enumerate(loader):\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            _ = model(images)\n",
    "            if (i + 1) * images.size(0) >= num_warmup:\n",
    "                break\n",
    "\n",
    "    # Timing\n",
    "    with torch.no_grad():\n",
    "        start = time.perf_counter()\n",
    "        for images, _ in loader:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            _ = model(images)\n",
    "            bs = images.size(0)\n",
    "            total_images += bs\n",
    "            if total_images >= max_images:\n",
    "                break\n",
    "        end = time.perf_counter()\n",
    "\n",
    "    total_time = end - start\n",
    "    avg_time_per_image = (total_time / total_images) * 1000.0  # ms\n",
    "    throughput = total_images / total_time  # img/s\n",
    "    return avg_time_per_image, throughput, total_images, total_time\n",
    "\n",
    "print(\"\\n===== MENGUKUR WAKTU INFERENSI (TEST SET, SUBSET) =====\")\n",
    "avg_ms, tpt, n_img, total_t = measure_inference_time(model, test_loader, DEVICE)\n",
    "print(f\"Images tested     : {n_img}\")\n",
    "print(f\"Total time        : {total_t:.4f} s\")\n",
    "print(f\"Avg time / image  : {avg_ms:.4f} ms\")\n",
    "print(f\"Throughput        : {tpt:.2f} images/s\")\n",
    "\n",
    "# Simpan ringkasan hasil ke CSV / TXT\n",
    "summary = {\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"total_params\": total_params,\n",
    "    \"trainable_params\": trainable_params,\n",
    "    \"non_trainable_params\": non_trainable_params,\n",
    "    \"model_size_mb\": model_size_mb,\n",
    "    \"best_val_acc\": best_val_acc,\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_acc\": test_acc,\n",
    "    \"avg_inference_ms\": avg_ms,\n",
    "    \"throughput_img_per_s\": tpt,\n",
    "    \"num_test_inference\": n_img,\n",
    "    \"total_inference_time_s\": total_t,\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame([summary])\n",
    "summary_path = f\"{MODEL_TAG}_summary.csv\"\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "print(f\"\\nSummary saved to: {summary_path}\")\n",
    "print(\"Selesai.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
